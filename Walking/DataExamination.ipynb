{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e7eae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Analyze the accelerometer data collected from a slipper walking on textured ground surfaces\n",
    "Created on 2024.03.16 (shaoyitian@hit.edu.cn)\n",
    "'''\n",
    "\n",
    "# %matplotlib notebook\n",
    "# %matplotlib notebook\n",
    "\n",
    "# Import packages\n",
    "import time\n",
    "from os import walk\n",
    "import os.path as ospa\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import mlab\n",
    "import pandas as pd\n",
    "import scipy.io as scio\n",
    "from scipy import signal\n",
    "# import seaborn as sns\n",
    "import IPython.display as ipd\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "from librosa.feature import mfcc\n",
    "\n",
    "''' Figure format'''\n",
    "plt.rc('font', size=16, family='Verdana') # 'Tahoma', 'DejaVu Sans', 'Verdana'\"\n",
    "plt.rc('axes', edgecolor='k', linewidth=0.75, labelcolor='k')\n",
    "plt.rc('axes.spines', **{'bottom':True, 'left':True, 'right':True, 'top':True})\n",
    "plt.rcParams['xtick.top'] = True\n",
    "plt.rcParams['xtick.bottom'] = True\n",
    "plt.rcParams['ytick.left'] = True\n",
    "plt.rcParams['ytick.right'] = True\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "plt.rcParams['errorbar.capsize'] = 4\n",
    "\n",
    "''' Define Color Here '''\n",
    "pltBlue = (32/255,120/255,180/255)\n",
    "pltRed = (180/255,32/255,32/255)\n",
    "\n",
    "''' Suppress warnings '''\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "''' \n",
    "General Settings\n",
    "'''\n",
    "AudioFs = 44100 # (Hz) Sampling frequency of the audio measurements\n",
    "\n",
    "'''\n",
    "General Functions\n",
    "'''\n",
    "\n",
    "def decodeData(fileName, decodeFormat, frontCode='', rearCode='', isString=False):\n",
    "    segStr = re.findall(frontCode+decodeFormat+rearCode, fileName)\n",
    "    if segStr:\n",
    "        decoded = re.findall(decodeFormat, segStr[0])[0]      \n",
    "        if isString:\n",
    "            return decoded  \n",
    "        return float(decoded)\n",
    "    return None\n",
    "\n",
    "def lowpassSmooth(datain, cutFreqRatio=0.05, order=8):\n",
    "    b, a = signal.butter(order, 2 * cutFreqRatio, btype='low')\n",
    "    dataout = signal.filtfilt(b, a, datain)\n",
    "    return dataout\n",
    "\n",
    "def highpassFilter(datain, cutFreqRatio=0.01, order=8):\n",
    "    b, a = signal.butter(order, 2 * cutFreqRatio, btype='high')\n",
    "    dataout = signal.filtfilt(b, a, datain)\n",
    "    return dataout\n",
    "\n",
    "def movAvgSmooth(datain, winLen=100):\n",
    "    dataout = np.convolve(datain, np.ones(winLen)/winLen, mode='same')\n",
    "    return dataout\n",
    "\n",
    "def segmentByEnergy(datain, segIntervalSamp, disp=False, threshold=0.1):\n",
    "    ''' This function segment the accelerometer data based on detecting the energy surge of the input signal '''\n",
    "    # 'datain' - a data vector used to determine the segmentation\n",
    "    # 'segIntervalSamp' - the number of samples for each detection window (sliding window length)\n",
    "    # 'disp' - display the segmentation result if True\n",
    "    # 'threshold' - the threshold to determine whether the energy has increased or decreased significantly\n",
    "    \n",
    "    dataEnergy = abs(datain-np.mean(datain)) # Energy of the acceleration signals\n",
    "    \n",
    "    smoothSig = movAvgSmooth(dataEnergy, segIntervalSamp) # Identify the energy fluctuation with moving-average smoothing\n",
    "        \n",
    "    samp = np.arange(len(datain)-1) # Shorten by 1 samples for indexing after computing the 1st difference\n",
    "    energyDiff = np.diff(smoothSig)\n",
    "    energyIncreaseInd = samp[energyDiff > threshold] # Index of samples when the energy increased significantly\n",
    "    energyDecreaseInd = samp[energyDiff < -threshold] # Index of samples when the energy decreased significantly\n",
    "    \n",
    "    tmp = energyIncreaseInd[:-1]\n",
    "    energySurgeUpInd = tmp[np.diff(energyIncreaseInd) > (segIntervalSamp * 0.5)] # Enforce a minimal duration bewteen two consecutive energy increasing intervals\n",
    "    \n",
    "    tmp = energyDecreaseInd[:-1]\n",
    "    energySurgeDownInd = tmp[np.diff(energyDecreaseInd) > (segIntervalSamp * 0.5)] # Enforce a minimal duration bewteen two consecutive energy decreasing intervals\n",
    "\n",
    "    if disp:\n",
    "        _,ax0 = plt.subplots(1,1,figsize=(14, 6),dpi=72); \n",
    "        ax0.plot(samp, datain[:-1], color='tab:grey'); \n",
    "        axb = ax0.twinx() \n",
    "        axb.plot(samp, smoothSig[:-1], color='tab:green') # Plot the smoothed signals\n",
    "        axb.tick_params(axis='y', labelcolor='tab:green')\n",
    "        ax0.plot(energySurgeUpInd, np.zeros(energySurgeUpInd.shape), '.r')\n",
    "        ax0.plot(energySurgeDownInd, np.zeros(energySurgeDownInd.shape), '.b')\n",
    "        plt.show();\n",
    "        \n",
    "    return energySurgeUpInd, energySurgeDownInd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0436ac39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Import and preprocessing of accelerometer measurements\n",
    "'''\n",
    "DataPath = './data2024.03'\n",
    "\n",
    "''' Import, metadata extraction, and segmentation '''\n",
    "\n",
    "segIntervalSamp = 600 # (samples) The window length used for onset detection and segmentation\n",
    "\n",
    "selectAxis = 2\n",
    "\n",
    "walkDF = [] # Dataframe of the walking measurements\n",
    "for root, directories, files in walk(DataPath):\n",
    "    for fileName in files:\n",
    "        if root is not None:\n",
    "            metaDataStings = root.split(\"\\\\\") # Acquire metadata from the root string of the data\n",
    "            majorType = metaDataStings[1] # The parent folder is named by the major surface type\n",
    "            subType = metaDataStings[2] # The child folder is named by the subcategory type\n",
    "\n",
    "            dataName = decodeData(fileName, '\\w+', frontCode='', rearCode='.csv', isString=True)\n",
    "            accFs = decodeData(fileName, '[\\d+\\.]*\\d+', frontCode='Fs', rearCode='Hz.csv')\n",
    "\n",
    "            if (dataName is not None) and (accFs is not None):\n",
    "                readData = pd.read_csv(ospa.join(root, fileName), header = None)\n",
    "                if readData is not None:\n",
    "                    accData = readData.to_numpy() # Convert data to a 2D numpy array with 3 columns containing channels X, Y, Z                   \n",
    "                    segIndPair = segmentByEnergy(accData[:,selectAxis], segIntervalSamp, disp=False)\n",
    "                    walkDF.append([majorType, subType, accData, accFs, segIndPair])\n",
    "                    \n",
    "walkDF = pd.DataFrame(walkDF, columns = ['MajorType','SubType','AccData','AccFs','SegmentIndex'])\n",
    "display(walkDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84063411",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Segment the data\n",
    "'''\n",
    "def segmentMultichannelData(datain, segmentingInd, disp=False, dispAxis=0, waterfallShift=1000):\n",
    "    if disp:\n",
    "        _,ax0 = plt.subplots(1,1,figsize=(14, 20),dpi=72); \n",
    "        ax0.set_xlabel('Samples')\n",
    "        ax0.set_ylabel(row['MajorType'])\n",
    "        \n",
    "    dataout = []\n",
    "    for i in range(len(segmentingInd)-1):\n",
    "        if(segmentingInd[i+1] - segmentingInd[i]) > minInterval:  # Discard the segment if it is shorter than 'minInterval'\n",
    "            segmentEndInd = min(segmentingInd[i+1], segmentingInd[i]+maxInterval) # Limit the segment length based on 'maxInterval'\n",
    "            dataSegment = datain[segmentingInd[i]:segmentEndInd,:] # Get the accelerometer data segment\n",
    "            if disp:\n",
    "                ax0.plot(dataSegment[:,-1]+(i*waterfallShift))\n",
    "            dataout.append(dataSegment)\n",
    "    return dataout\n",
    "\n",
    "''' Settings '''\n",
    "minInterval = 900 # (samples) the minimum interval between two consecutive foot steps\n",
    "maxInterval = 1300 # (samples) the maximum interval between two consecutive foot steps\n",
    "\n",
    "datasegDF = [] # Dataframe of the segmented data to be used for classification\n",
    "for index, row in walkDF.iterrows():\n",
    "    segmentingInd = row['SegmentIndex'][1] # Use 'energySurgeDownInd' to segment the data\n",
    "    accSegment = segmentMultichannelData(row['AccData'], segmentingInd, disp=False, dispAxis=2, waterfallShift=1000)\n",
    "    datasegDF.append([row['MajorType'],row['SubType'],accSegment,row['AccFs']])\n",
    "datasegDF = pd.DataFrame(datasegDF, columns = ['MajorType','SubType','AccSegment','AccFs'])\n",
    "display(datasegDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75838e00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Feature extraction for classification\n",
    "'''\n",
    "display(datasegDF['MajorType']) # The index for each class label\n",
    "\n",
    "selectAxis = 0\n",
    "dataFeature = []\n",
    "for index, row in datasegDF.iterrows():\n",
    "    accSegment = row['AccSegment']\n",
    "    \n",
    "    for seg in accSegment:\n",
    "        \n",
    "        timeAvg = np.sqrt(np.mean(seg[:,selectAxis]**2)) # Time-averaged energy of ?-axis data\n",
    "        \n",
    "        timePeak = np.max(abs(seg[:,selectAxis])) # ?-axis peak\n",
    "        \n",
    "        filteredData = highpassFilter(seg[:,selectAxis], cutFreqRatio=0.01, order=8)\n",
    "        \n",
    "        spectr, f, _ = plt.magnitude_spectrum(filteredData, Fs=row['AccFs'], window=mlab.window_none);\n",
    "        centerFreq = np.dot(spectr/np.sum(spectr), f)\n",
    "\n",
    "        dataFeature.append([timeAvg, timePeak, centerFreq, index])\n",
    "dataFeature = np.array(dataFeature)\n",
    "\n",
    "featureNum = dataFeature.shape[1]-1\n",
    "\n",
    "# fig = plt.figure(figsize=(14, 12))\n",
    "# ax3D = fig.add_subplot(projection='3d')\n",
    "_,ax = plt.subplots(featureNum,1,figsize=(14, 8),dpi=72); \n",
    "for i in range(8):\n",
    "    aSurfaceType = dataFeature[dataFeature[:,-1]==i]\n",
    "    print(\"%s %s\" % (datasegDF.loc[i,'MajorType'], aSurfaceType.shape))\n",
    "    for j in range(featureNum):\n",
    "        ax[j].boxplot(aSurfaceType[:,j], positions=[i])\n",
    "for j in range(featureNum):\n",
    "    ax[j].set_xticklabels(datasegDF['MajorType'])\n",
    "#     ax3D.scatter(aSurfaceType[:,0], aSurfaceType[:,1], aSurfaceType[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f8c5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccFeature = librosa.feature.mfcc(y=filteredData, sr=row['AccFs'], n_mfcc=4)\n",
    "print(mfccFeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba790bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Classification\n",
    "'''\n",
    "from sklearn import svm\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "X = dataFeature[:,:-1]\n",
    "y = dataFeature[:,-1]\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.80, test_size=0.20, random_state=101)\n",
    "\n",
    "rbf = OneVsRestClassifier(svm.SVC(kernel='rbf', gamma=0.001, C=1)).fit(X_train, y_train)\n",
    "rbf_pred = rbf.predict(X_test)\n",
    "\n",
    "rbf_accuracy = accuracy_score(y_test, rbf_pred)\n",
    "rbf_f1 = f1_score(y_test, rbf_pred, average='weighted')\n",
    "print(\"Accuracy: %.2f%%, F1: %.2f%%\" % (rbf_accuracy*100, rbf_f1*100))\n",
    "\n",
    "for i in range(8):\n",
    "    ind = (y_test==i)\n",
    "    rbf_accuracy = accuracy_score(y_test[ind], rbf_pred[ind])\n",
    "    rbf_f1 = f1_score(y_test[ind], rbf_pred[ind], average='weighted')\n",
    "    print(\"%s (%d samples) - Accuracy: %.2f%%, F1: %.2f%%\" % (datasegDF.loc[i,'MajorType'],sum(ind),rbf_accuracy*100, rbf_f1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdb0626",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
